[
  {
    "question_id":"skillcertpro_e3_q1",
    "question": "You are working with multiple machine learning models built using different frameworks (e.g., TensorFlow, Scikit-learn, and PyTorch). You want to deploy these models using MLflow. Which of the following statements best describes MLflow Flavors and their benefits in this scenario?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "MLflow Flavors are a type of data augmentation method used to enrich datasets during training."},
      {"id": 1, "text": "MLflow Flavors provide a unified interface for running different types of models built in various frameworks, enabling deployment in diverse environments."},
      {"id": 2, "text": "MLflow Flavors allow you to convert models between different frameworks, such as converting a TensorFlow model into a PyTorch model."},
      {"id": 3, "text": "MLflow Flavors optimize model hyperparameters automatically during the training process."}
    ],
    "ans_id":1,
    "explanation":"MLflow Flavors provide a unified interface for running different types of models built in various frameworks, enabling deployment in diverse environments.\n\n-Framework independence: You can package and deploy models written in different frameworks without worrying about specific deployment configurations. \n-Reusability: Flavors help in versioning and managing models across diverse environments and use cases. \n-Consistency: By using MLflow flavors, organizations can standardize how models are handled across teams, making collaboration and deployment more efficient."
  },
  {
    "question_id":"skillcertpro_e3_q2",
    "question": "You have a machine learning model already registered in the Databricks Model Registry. The model has undergone several iterations, each registered as a new version. The team wants to track critical information about each version, such as its training dataset and evaluation metrics. You need to add this metadata in a way that it is accessible for both auditing and future model improvement. What are the appropriate ways to add and manage metadata for a specific model version in Databricks? (Select two)",
    "type":"MS",
    "choices": [
      {"id": 0, "text": "Attach tags with metadata such as 'Training Dataset' and 'Accuracy' to the model version using mlflow.set_tag()."},
      {"id": 1, "text": "Leverage mlflow.log_model() to log the model along with its metadata in a single step."},
      {"id": 2, "text": "Edit the model versions 'Description' field directly in the Model Registry UI to add training and evaluation information."},
      {"id": 3, "text": "Run a new MLflow experiment and use mlflow.log_params() to log the metadata that will be automatically added to the new model version."},
      {"id": 4, "text": "Use the mlflow.update_registered_model() method to append metadata to the model version."}
    ],
    "ans_ids":[0,2],
    "explanation":"Attach tags with metadata such as 'Training Dataset' and 'Accuracy' to the model version using mlflow.set_tag().\n MLflow tags provide a flexible way to add key-value metadata to various MLflow objects, including registered model versions. Using mlflow.set_tag() allows you to programmatically attach information like the training dataset used, evaluation metrics, or any other relevant details directly to a specific version of the model. These tags are easily viewable in the Model Registry UI and accessible via the MLflow API for auditing and analysis.\n\n Edit the model versions 'Description' field directly in the Model Registry UI to add training and evaluation information.\nThe Model Registry UI provides a 'Description' field for each registered model version. This field allows users to manually enter free-form text to document important details about the model version, such as the training process, evaluation results, or any other relevant context. While not as structured as tags, it offers a straightforward way to add and view descriptive metadata directly within the UI."
  },
  {
    "question_id":"skillcertpro_e3_q3",
    "question": "You are tasked with converting a batch inference pipeline that predicts equipment failures based on sensor data collected from factory machines. The batch pipeline currently processes data collected every day and outputs predictions for potential equipment failures. To improve response times, the company wants to switch to a streaming deployment where predictions are generated as sensor data flows continuously into the system. The current pipeline uses daily averages, maximum values, and rolling statistics as features for model inference. Which of the following strategies is most appropriate for converting the batch pipeline into a streaming deployment?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Use a micro-batch approach to compute rolling statistics at fixed intervals and feed them into the streaming model."},
      {"id": 1, "text": "Drop the rolling statistics and compute only real-time averages and maximum values on each sensor event."},
      {"id": 2, "text": "Use structured streaming with stateful operations to track sensor data and compute rolling statistics in real time."},
      {"id": 3, "text": "Continue using the batch pipeline but execute it more frequently using a cron job to simulate streaming behavior."}
    ],
    "ans_id":2,
    "explanation":" Use structured streaming with stateful operations to track sensor data and compute rolling statistics in real time.\n\n Structured Streaming in Databricks provides the capability for stateful stream processing. To compute rolling statistics (like rolling averages, maximums) in a streaming environment, you need to maintain state across the incoming data stream. Stateful operations in Structured Streaming allow you to track data over time windows and perform calculations like rolling averages, maximums, and other aggregations in a continuous and real-time manner. This approach allows you to replicate the feature engineering done in the batch pipeline (using rolling statistics) in the streaming pipeline, ensuring the model receives similar input features for inference in real time."
  },
  {
    "question_id":"skillcertpro_e3_q4",
    "question": "You are working as a data scientist at a company using Databricks and MLflow to track machine learning experiments. You have trained multiple versions of a regression model to predict housing prices and logged them as different runs in an MLflow experiment. After several iterations, you want to compare the performance of these models based on their logged metrics and extract the metadata to visualize their parameters and evaluate which version should be deployed. You write the following code to retrieve the logged models:\n\nimport mlflow\nfrom mlflow.tracking import MlflowClient\n# Initialize MLflow client\nclient = MlflowClient()\n# Fetch experiment by name\nexperiment = client.get_experiment_by_name('Housing Price Prediction')\n# Fetch all runs in the experiment\nruns = client.search_runs(experiment.experiment_id)\n# Filter for best-performing run based on R2 score\nbest_run = max(runs, key=lambda run: run.data.metrics['r2_score'])\n# Load model from best run\nmodel_uri = f'runs:/{best_run.info.run_id}/model'\nmodel = mlflow.pyfunc.load_model(model_uri)\n\nWhich of the following options best explains how the code works and whether it correctly retrieves and loads the best-performing model based on the R2 score?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "The code will throw an error when filtering runs by R2 score because the key 'r2_score' is not valid unless the metric is explicitly defined using a custom metric logger"},
      {"id": 1, "text": "The code correctly retrieves all runs from the 'Housing Price Prediction' experiment and successfully loads the model from the run with the highest R2 score."},
      {"id": 2, "text": "The code is incorrect because MLflow does not support the loading of models based on the R2 score from a run. Instead, you should load the model directly using the model's URI stored in the artifact location."},
      {"id": 3, "text": "The code correctly retrieves all runs from the experiment, but it will fail because the search_runs() method returns an iterator, which does not support the max function."}
    ],
    "ans_id":1,
    "explanation":"B. The code correctly retrieves all runs from the 'Housing Price Prediction' experiment and successfully loads the model from the run with the highest R2 score.\n\n The provided code snippet is logically sound for retrieving and loading the best-performing model based on the logged 'r2_score' metric.It correctly initializes the MlflowClient to interact with the MLflow tracking server.It fetches the experiment ID using the experiment name.client.search_runs(experiment.experiment_id) will indeed return a list of Run objects corresponding to all the runs within the specified experiment. Each Run object contains information about the run, including its parameters, metrics, tags, and artifact locations.The max() function with the key argument iterates through the list of Run objects. For each run, run.data.metrics['r2_score'] accesses the value of the 'r2_score' metric logged during that run. The max() function then returns the Run object that has the highest value for this metric.The model_uri is correctly constructed using the runs:/ format, which is a valid way to specify the location of a model logged within an MLflow run.mlflow.pyfunc.load_model(model_uri) is the standard way to load a Python function model (which is a common format for MLflow models) from the specified URI. Therefore, assuming that the 'r2_score' metric was correctly logged for each run in the experiment, the code will successfully identify the run with the highest R2 score and load the corresponding model."
  },
  {
    "question_id":"skillcertpro_e3_q5",
    "question": "You have conducted several experiment runs using MLflow in Databricks and want to find the best-performing model based on a custom evaluation metric (e.g., F1-score). Which MLflow feature is most appropriate for efficiently comparing these metrics across all runs?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Using the MLflow autologging feature"},
      {"id": 1, "text": "Using the MLflow Search API with custom metric-based queries"},
      {"id": 2, "text": "Reviewing the metrics in the MLflow Run Details view for each individual run"},
      {"id": 3, "text": "Manually comparing the models in Databricks notebooks"}
    ],
    "ans_id":1,
    "explanation":"Using the MLflow Search API with custom metric-based queries \n\n The MLflow Search API, specifically the mlflow.search_runs() function (or client.search_runs() for the tracking client), is the most efficient way to programmatically query and compare metrics across multiple MLflow runs. You can construct queries that filter runs based on the values of logged metrics, including custom metrics like F1-score. This allows you to easily identify the runs that achieved the highest F1-score or meet other performance criteria. The API returns a structured result (e.g., a Pandas DataFrame or a list of Run objects) that you can then use for further analysis and comparison."
  },
  {
    "question_id":"skillcertpro_e3_q6",
    "question": "You are working on a machine learning project where the model must be regularly updated with new data. Your organization uses MLflow to manage the lifecycle of machine learning models. Recently, there have been changes to the business logic, and your team has adopted a new data processing pipeline. One of your responsibilities is to ensure that the trained model behaves consistently across different environments (e.g., local development, staging, and production) despite the new changes in data preprocessing. Given this scenario, what is the primary advantage of using the pyfunc MLflow flavor to manage your model?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "The pyfunc flavor enables seamless switching between different model types, such as TensorFlow, PyTorch, and Scikit-learn, without modifying the code."},
      {"id": 1, "text": "The pyfunc flavor automatically optimizes your model for performance when deployed to different cloud environments, such as AWS, Azure, or GCP."},
      {"id": 2, "text": "The pyfunc flavor allows you to define custom Python-based preprocessing logic that will be executed consistently before model inference, regardless of the serving environment."},
      {"id": 3, "text": "The pyfunc flavor is used to ensure that models are versioned appropriately in MLflow, allowing for easy rollback to previous versions of the model."}
    ],
    "ans_id":2,
    "explanation":"The pyfunc flavor allows you to define custom Python-based preprocessing logic that will be executed consistently before model inference, regardless of the serving environment.\n\nThe primary advantage of the pyfunc MLflow flavor in this scenario is its ability to encapsulate not just the trained model but also any custom Python code required for preprocessing (and potentially postprocessing). By defining your preprocessing steps within the pyfunc model's predict method (or a custom load_context and predict structure), you ensure that the exact same transformations applied during training are also applied during inference, regardless of whether the model is being served locally, in a staging environment, or in production on Databricks or another platform. This consistency is crucial for avoiding discrepancies and ensuring reliable model behavior despite changes in the underlying data processing pipeline."
  },
  {
    "question_id":"skillcertpro_e3_q7",
    "question": "Your team is reviewing several models stored in the MLflow Model Registry, and you are tasked with determining which model is suitable for immediate deployment to production. Based on the model stages in the registry, which of the following best describes the appropriate use case for each stage in the lifecycle of a model?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "'None' is for models that are registered but not yet tested, 'Staging' is for models under testing or evaluation, and 'Production' is for models currently deployed in live environments."},
      {"id": 1, "text": "'None' is for models that are fully tested but not yet deployed, 'Staging' is for models currently serving in production environments, and 'Production' is for deprecated models."},
      {"id": 2, "text": "'None' is for deprecated models, 'Staging' is for models currently under production, and 'Production' is for models in the testing phase."},
      {"id": 3, "text": "'None' is for models currently being tested, 'Staging' is for models deployed in production, and 'Production' is for models archived for historical purposes."}
    ],
    "ans_id":0,
    "explanation":"'None' is for models that are registered but not yet tested, 'Staging' is for models under testing or evaluation, and 'Production' is for models currently deployed in live environments.\n\n-'None': Models in this stage are registered but have not been tested or promoted yet. They are not ready for production and may still need further validation.\n-'Staging': This stage is where models are evaluated and tested, usually in a non-production environment. It is common to run experiments and validate performance in the staging stage before promoting the model.\n-'Production': This is the stage for models currently deployed and actively serving in production environments. It is typically reserved for models that have passed all validations and are serving live traffic."
  },
  {
    "question_id":"skillcertpro_e3_q8",
    "question": "Your team is building a recommendation engine for an e-commerce platform. The model needs to process and analyze real-time user behavior, including clicks, purchases, and session durations, which are streamed into Databricks from a Kafka queue. To maintain high model performance and reliability, you need to design a solution that not only predicts in real-time but also monitors model performance and data quality at scale. Which solution architecture would best address the need for both real-time inference and continuous model monitoring?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Stream data into Databricks, deploy the model using MLflow for tracking, and use Delta Live Tables to monitor data quality and drift."},
      {"id": 1, "text": "Use a batch processing pipeline in Databricks and evaluate the models performance every week on aggregated data."},
      {"id": 2, "text": "Deploy the model using a local Flask server and manually inspect logs for any performance anomalies."},
      {"id": 3, "text": "Stream data directly into a machine learning model hosted on an EC2 instance, retraining the model every time the dataset grows by 5%."}
    ],
    "ans_id":0,
    "explanation":" Stream data into Databricks, deploy the model using MLflow for tracking, and use Delta Live Tables to monitor data quality and drift.\n\nThis architecture provides a comprehensive solution for real-time inference and continuous monitoring at scale within the Databricks ecosystem. \n-Stream data into Databricks: Databricks Structured Streaming is well-suited for processing real-time data from sources like Kafka.\n-Deploy the model using MLflow for tracking: MLflow provides robust tools for managing and deploying machine learning models, ensuring versioning and reproducibility for the real-time inference service.\n-Use Delta Live Tables (DLT) to monitor data quality and drift: DLT offers a declarative way to build and manage data pipelines, including built-in expectations for data quality monitoring. It can also be used to track changes in data distributions over time, which is crucial for detecting feature drift in the streaming data that feeds the real-time model. This allows for proactive identification of issues that might impact model performance."
  },
  {
    "question_id":"skillcertpro_e3_q9",
    "question": "Which of the following is a key advantage of using job clusters over all-purpose clusters when scaling machine learning workloads in Databricks?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Job clusters can be paused and resumed without restarting."},
      {"id": 1, "text": "Job clusters allow for persistent storage of results between jobs."},
      {"id": 2, "text": "Job clusters support multiple concurrent interactive users."},
      {"id": 3, "text": "Job clusters can be customized per job, ensuring consistency in dependencies."}
    ],
    "ans_id":3,
    "explanation":"Job clusters can be customized per job, ensuring consistency in dependencies.\n\nWhen scaling machine learning workloads, especially automated pipelines, job clusters offer the advantage of being configurable specifically for the needs of each individual job. This includes installing the exact libraries and dependencies required for that particular workload. This per-job customization ensures a consistent execution environment, reducing the risk of dependency conflicts that can arise in shared, all-purpose clusters where different users or jobs might have different library requirements. This consistency is crucial for the reliability and reproducibility of scaled ML workloads."
  },
  {
    "question_id":"skillcertpro_e3_q10",
    "question": "Your team has deployed a real-time fraud detection model for a financial services company. The model was trained on historical transaction data, but over the last few months, you observe a gradual increase in false positives. After investigating, you find that fraudsters have adapted their techniques, leading to shifts in fraudulent transaction patterns. What is the best approach to mitigate this concept drift and maintain the models performance?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Apply feature scaling techniques (e.g., normalization and standardization) to address the changes in the distribution of input features, ensuring consistent model performance."},
      {"id": 1, "text": "Introduce an adaptive learning algorithm that continuously updates the model weights based on a stream of new data to quickly respond to changing fraud patterns."},
      {"id": 2, "text": "Periodically retrain the model with the latest data to reflect the new fraud patterns, ensuring the model remains aligned with current fraudulent behaviors."},
      {"id": 3, "text": "Implement a model ensemble that combines predictions from multiple models trained on different time windows to average out the effects of drift."}
    ],
    "ans_id":1,
    "explanation":"Introduce an adaptive learning algorithm that continuously updates the model weights based on a stream of new data to quickly respond to changing fraud patterns.\n\nConcept drift refers to a change in the underlying relationship between the input features and the target variable (fraudulent vs. non-fraudulent). In this scenario, fraudsters are changing their techniques, so the patterns the model learned might no longer be valid. An adaptive learning algorithm is designed to continuously learn from new incoming data, adjusting the model's weights and potentially its structure in real time or near real-time. This allows the model to adapt to the evolving fraud patterns quickly without waiting for a full retraining cycle, thus mitigating the impact of concept drift and maintaining performance."
  }
]