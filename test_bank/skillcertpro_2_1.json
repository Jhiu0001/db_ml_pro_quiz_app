[
  {
    "question_id":"skillcertpro_e2_q1",
    "question": "You are optimizing a machine learning model using Hyperopt for hyperparameter tuning in Databricks. To ensure that all the experiments and model parameters are automatically tracked, you decide to enable MLflow autologging. You want to capture all hyperparameters, metrics, and model information from each trial in Hyperopt without manually logging each one. How should you correctly enable autologging in your experiment so that MLflow captures the necessary information during hyperparameter optimization?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Manually track the hyperparameters and results in a separate file and then use mlflow.log_artifact() to log the file after the experiment is complete."},
      {"id": 1, "text": "Set up a callback function in Hyperopt to log metrics after each trial, then call mlflow.autolog() in the callback function."},
      {"id": 2, "text": "Simply call mlflow.autolog() at the beginning of the experiment, and MLflow will automatically capture all hyperparameters and metrics from Hyperopt."},
      {"id": 3, "text": "Use mlflow.start_run() before each Hyperopt trial and manually log the hyperparameters and metrics using mlflow.log_param() and mlflow.log_metric() functions."}
    ],
    "ans_id":0,
    "explanation":"Simply call mlflow.autolog() at the beginning of the experiment, and MLflow will automatically capture all hyperparameters and metrics from Hyperopt.\n\n MLflow's autologging feature is designed to automatically track parameters, metrics, and artifacts from various machine learning libraries, including Hyperopt, without the need for explicit logging statements within your training code. By calling mlflow.autolog() at the start of your script or notebook, MLflow hooks into the training process of supported libraries and automatically records relevant information for each run. This includes hyperparameters explored by Hyperopt and the resulting evaluation metrics."
  },
  {
    "question_id":"skillcertpro_e2_q2",
    "question": "You want to automate the transition of a model version to the 'Production' stage when its corresponding model version is promoted to the 'Staging' stage in the Databricks Model Registry. Which approach would correctly use the Model Registry Webhooks to achieve this?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Use a Model Registry Webhook with an event trigger set to 'MODEL_VERSION_TRANSITIONED_STAGE' to detect when a model is promoted to 'Staging,' and then programmatically transition it to 'Production' using a Databricks Job."},
      {"id": 1, "text": "Create a Databricks Job to constantly monitor the Model Registry for any changes in stage and use mlflow.register_model() to promote the model version to 'Production' when detected."},
      {"id": 2, "text": "Manually set up a pipeline that checks the 'Staging' stage every few minutes and transitions models to 'Production' using mlflow.transition_model_version_stage()."},
      {"id": 3, "text": "Use Databricks Workflows to automatically move a model to 'Production' once it is deployed in 'Staging' without the need for Webhooks or any event-driven systems."}
    ],
    "ans_id":0,
    "explanation":"Use a Model Registry Webhook with an event trigger set to 'MODEL_VERSION_TRANSITIONED_STAGE' to detect when a model is promoted to 'Staging,' and then programmatically transition it to 'Production' using a Databricks Job. This approach correctly uses Model Registry Webhooks for event-driven automation. Webhook Trigger: Setting the event trigger to 'MODEL_VERSION_TRANSITIONED_STAGE' ensures that the webhook is activated whenever a model version's stage changes. Detecting 'Staging' Promotion: The webhook payload will contain information about the transitioned stage, allowing your receiving service (e.g., a Databricks Job endpoint or an external service) to identify when a model has moved to 'Staging.'Programmatic Transition to 'Production': The Databricks Job, triggered by the webhook, can then use the MLflow API (specifically mlflow.transition_model_version_stage()) to programmatically transition the same model version to the 'Production' stage. This creates an automated flow based on the desired condition."
  },
  {
    "question_id":"skillcertpro_e2_q3",
    "question": "You are managing a machine learning pipeline in Databricks that needs to retrain a model daily with newly ingested data. Your goal is to minimize infrastructure costs while ensuring that the retraining jobs run efficiently. You have two options for this automation: using a Job cluster or an all-purpose cluster. Which option provides the best balance between cost and performance for this scenario?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Use an all-purpose cluster because it supports concurrent users and multiple notebooks, allowing you to leverage its versatility for various tasks, including retraining."},
      {"id": 1, "text": "Use an all-purpose cluster because it allows you to retain the cluster state between jobs, making it more efficient for repeated retraining tasks."},
      {"id": 2, "text": "Use a Job cluster because it is created for each job and automatically terminated after completion, reducing unnecessary costs."},
      {"id": 3, "text": "Use an all-purpose cluster because it allows you to scale horizontally, whereas Job clusters can only scale vertically."}
    ],
    "ans_id":2,
    "explanation":"Use a Job cluster because it is created for each job and automatically terminated after completion,reducing unnecessary costs.\n\n For an automated, scheduled task like daily model retraining, Job clusters offer a significant cost advantage. They are ephemeral, meaning they are spun up only when the job needs to run and are automatically terminated once the job is finished. This prevents incurring costs for idle compute resources, which would be the case with a continuously running all-purpose cluster. While there's a small overhead of cluster startup time for each job, for daily retraining tasks, the savings from automatic termination typically outweigh this."
  },
  {
    "question_id":"skillcertpro_e2_q4",
    "question": "You have a feature table in Databricks Feature Store that contains customer transaction history, but the table is missing some key transactions from recent days. You receive an incremental dataset with the missing transactions, and you want to merge it into the existing feature table. What is the most appropriate way to perform this merge while maintaining the integrity of both old and new data in the Feature Store?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Use the merge operation to combine the new transactions with the old table, ensuring that duplicate records are updated."},
      {"id": 1, "text": "Drop the existing feature table and create a new one with both old and new transactions."},
      {"id": 2, "text": "Append the new transactions directly to the feature table without performing any deduplication."},
      {"id": 3, "text": "Overwrite the entire feature table with the combined dataset of old and new transactions."}
    ],
    "ans_id":0,
    "explanation":"Use the merge operation to combine the new transactions with the old table, ensuring that duplicate records are updated.\n\n The merge operation in Databricks Feature Store is designed for exactly this scenario. It allows you to combine a source DataFrame (the incremental dataset with missing transactions) into a target Delta table (your existing feature table) based on a specified join condition (e.g., transaction ID). \n-Updating Existing Records: The merge operation can update existing records in the target table if a match is found in the source data. This is important if the incremental dataset might contain corrections or updates to previously ingested transactions.\n-Inserting New Records: It also inserts new records from the source that do not have a match in the target, effectively adding the missing transactions.\n-Maintaining Integrity: By using a proper join condition and specifying how to handle matches and non matches, merge ensures that the integrity of both the old and new data is maintained, avoiding duplicates and allowing for updates."
  },
  {
    "question_id":"skillcertpro_e2_q5",
    "question": "You have a machine learning workflow that reads data from a Feature Store table to train a model. You want to ensure that the data is always fresh, incorporating the latest updates from an external data source. Which is the best method to achieve this, considering performance and data consistency?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "read_as_of"},
      {"id": 1, "text": "stream_read"},
      {"id": 2, "text": "refresh_table"},
      {"id": 3, "text": "time_travel_read"}
    ],
    "ans_id":2,
    "explanation":"refresh_table \n\nThe refresh_table operation in Databricks Feature Store is the recommended way to ensure that the feature table reflects the latest updates from its underlying data sources. When you call refresh_table on a Feature Store table, it triggers an update process that reads the most recent data from the source tables and updates the feature table accordingly. This ensures data freshness for model training."
  },
  {
    "question_id":"skillcertpro_e2_q6",
    "question": "You are processing IoT sensor data using Structured Streaming in Databricks. The events sometimes arrive out-of-order or even multiple times due to network issues. You want to ensure your pipeline produces an accurate result by deduplicating the data based on the event time and unique sensor ID. What is the best strategy to deduplicate events and handle late arrivals?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Deduplicate based on the processing time and sensor ID to ensure real-time processing."},
      {"id": 1, "text": "Use a sliding window function to track event occurrences and discard duplicates in real-time."},
      {"id": 2, "text": "Deduplicate the data using event time and apply a watermark with a duration longer than the expected delay of late events."},
      {"id": 3, "text": "Use global aggregation without windowing and rely on the default deduplication logic of Structured Streaming."}
    ],
    "ans_id":2,
    "explanation":"Deduplicate the data using event time and apply a watermark with a duration longer than the expected delay of late events.\n\nhis strategy provides the most accurate deduplication while accounting for late arrivals in a Structured Streaming pipeline.\n-Event Time: Deduplicating based on event time (the timestamp in the IoT sensor data) ensures that you are identifying duplicates based on when the event actually occurred, regardless of when it was processed.\n-Unique Sensor ID: Combining event time with a unique sensor ID provides a robust key for identifying duplicate events. An event from the same sensor at the same time is highly likely to be a duplicate.\n-Watermarking: Applying a watermark with a duration longer than the expected delay of late events allowsthe streaming engine to wait for a reasonable amount of time for potentially out-of-order or delayed eventsto arrive before considering them for deduplication. This prevents prematurely dropping valid, albeit late,data"
  },
  {
    "question_id":"skillcertpro_e2_q7",
    "question": "What is the primary benefit of integrating automated testing into a CI/CD pipeline for machine learning models?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Ensuring that the model's hyperparameters remain fixed between versions."},
      {"id": 1, "text": "Detecting model drift as early as possible in the pipeline."},
      {"id": 2, "text": "Guaranteeing that the model will always generalize well to unseen data."},
      {"id": 3, "text": "Minimizing the need for manual testing and monitoring after each deployment."}
    ],
    "ans_id":3,
    "explanation":"Minimizing the need for manual testing and monitoring after each deployment.\n\n The primary benefit of integrating automated testing into an ML CI/CD pipeline is to automate the verification of model quality, performance, and stability at various stages (e.g., after training, before deployment). This automation reduces the reliance on manual testing and monitoring, making the deployment process faster, more reliable, and less prone to human error. Automated tests can cover aspects like data quality, model performance on held-out sets, integration with other systems, and even basic sanity checks, ensuring a certain level of confidence in the deployed model."
  },
  {
    "question_id":"skillcertpro_e2_q8",
    "question": "You are responsible for setting up model monitoring in Databricks to automate alerts when a model performance drops below a certain threshold. To achieve this, you want to configure a webhook that triggers an external service to notify the engineering team when the performance metrics degrade. Which of the following steps are required to configure a webhook in Databricks to automate this workflow?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Create an HTTP endpoint in Databricks, set up the webhook in the Jobs API, and link it with the Databricks Repos feature to manage code updates."},
      {"id": 1, "text": "Create a webhook in the Databricks Jobs UI, define the triggering event, and configure the HTTP request for the external service, specifying authentication headers if required."},
      {"id": 2, "text": "Set up the webhook via Databricks Clusters API and configure cluster events to trigger the HTTP request automatically upon job completion."},
      {"id": 3, "text": "Create a Databricks Job, configure the webhook to call an external API endpoint, and specify the HTTP method and payload format."}
    ],
    "ans_id":1,
    "explanation":"Create a webhook in the Databricks Jobs UI, define the triggering event, and configure the HTTP request for the external service, specifying authentication headers if required.\n\n Databricks provides the capability to set up webhooks directly within the Jobs UI. This allows you to define specific events (such as job failure or success) that should trigger an HTTP POST request to a specified external service endpoint. You can configure the URL of the external service, the HTTP method (typically POST), headers (including authentication if needed), and the payload that will be sent when the triggering event occurs. This directly addresses the requirement of automating alerts to an external service when model performance (monitored by a Databricks Job) drops below a threshold (which would likely lead to a job failure or a specific metric being logged)."
  },
  {
    "question_id":"skillcertpro_e2_q9",
    "question": "You are monitoring a production machine learning model that uses both categorical and numeric features. You suspect that one of the categorical features, 'User Device Type' (with categories such as 'Mobile','Desktop', 'Tablet'), may be experiencing drift over time. Which of the following tests would be the most appropriate for detecting drift in this categorical feature?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Chi-Square Test"},
      {"id": 1, "text": "Kolmogorov-Smirnov (K-S) Test"},
      {"id": 2, "text": "Wasserstein Distance"},
      {"id": 3, "text": "T-Test"}
    ],
    "ans_id":0,
    "explanation":"Chi-Square Test\n\n The Chi-square test is the most appropriate statistical test for detecting drift in categorical features. It compares the observed frequencies of each category in the current data with the expected frequencies from a baseline period (e.g., training data or a previous time window). A statistically significant Chi-square statistic indicates that the difference in the distributions of the categorical feature is unlikely due to random chance, suggesting drift."
  },
  {
    "question_id":"skillcertpro_e2_q10",
    "question": "You are tasked with monitoring the data quality of a feature called product_category, which is a categorical feature in your model. Recently, you've noticed that some categories are underrepresented, and there are a few missing values in your incoming data. You want to implement a simple solution to monitor feature drift in product_category. What would be the most effective approach to identify drift and data quality issues?",
    "type":"MC",
    "choices": [
      {"id": 0, "text": "Apply Principal Component Analysis (PCA) to reduce dimensionality in product_category"},
      {"id": 1, "text": "Ignore the missing values and track only the unique categories"},
      {"id": 2, "text": "Calculate the percentage of missing values and track unique categories over time"},
      {"id": 3, "text": "Use the Z-test to compare means of categories"}
    ],
    "ans_id":2,
    "explanation":"Calculate the percentage of missing values and track unique categories over time\n\nThis approach directly addresses both the data quality issue (missing values) and the potential for drift in the categorical feature.\n-Percentage of Missing Values: Tracking the percentage of missing values over time will help you identify if the data quality is deteriorating. A sudden increase in missing values could indicate a problem in the data pipeline.\n-Tracking Unique Categories: Monitoring the set of unique categories and their proportions over time can reveal drift. New categories might appear, existing categories might disappear or become underrepresented, indicating a shift in the data distribution."
  }
]